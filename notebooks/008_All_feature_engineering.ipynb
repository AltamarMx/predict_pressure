{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e71a1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 16:58:35.569100: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "import glob as glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dd5291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtra(lista):\n",
    "    m3x3 = []\n",
    "    mNxN = []\n",
    "    for var in lista:\n",
    "        if var[2]==(14751,3,3):\n",
    "            m3x3.append(var)\n",
    "        else:\n",
    "            mNxN.append(var)\n",
    "    return m3x3,mNxN\n",
    "\n",
    "def desde3x3(m):\n",
    "    a = np.load(m)\n",
    "    a_00 = a[:, 0, 0]\n",
    "    a_01 = a[:, 0, 1]\n",
    "    a_02 = a[:, 0, 2]\n",
    "    a_10 = a[:, 1, 0]\n",
    "    a_11 = a[:, 1, 1]\n",
    "    a_12 = a[:, 1, 2]\n",
    "    a_20 = a[:, 2, 0]\n",
    "    a_21 = a[:, 2, 1]\n",
    "    a_22 = a[:, 2, 2]\n",
    "    resultado = np.column_stack((a_00, a_01, a_02, a_10, a_11, a_12, a_20, a_21, a_22))    \n",
    "    return resultado\n",
    "\n",
    "\n",
    "def desde3x3_nombre(m):\n",
    "    nombre = []\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            nombre.append(m[0]+\"_\"+str(i)+str(j))\n",
    "    return nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c6eb042",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = glob.glob(\"../data/kepsilon/kepsilon_PHLL_case_1p0*\")\n",
    "\n",
    "\n",
    "vars_1d  = [(variable[40:-4],variable,np.load(variable).shape)for variable in variables if np.load(variable).shape==(14751,)]\n",
    "vars_Nd = [(variable[40:-4],variable,np.load(variable).shape)for variable in variables if np.load(variable).shape!=(14751,)]\n",
    "\n",
    "m3x3,mNxN = filtra(vars_Nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ffdd5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m3x3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "182a289e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vars_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2dcaaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres= list(chain.from_iterable([desde3x3_nombre(m) for m in m3x3]))\n",
    "m3x3 = np.column_stack([desde3x3(m[1]) for m in m3x3])\n",
    "m3x3 = pd.DataFrame(m3x3,columns=nombres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dd33c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres   = [var[0] for var in vars_1d]\n",
    "archivos = [var[1] for var in vars_1d]\n",
    "\n",
    "m1d = pd.DataFrame(np.column_stack([np.load(archivo) for archivo in archivos]),columns=nombres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c028b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([m1d,m3x3],axis=1)\n",
    "del data[\"Cx\"]\n",
    "del data[\"Cy\"]\n",
    "del data[\"Cz\"]\n",
    "del data[\"gradpy\"]\n",
    "del data[\"gradpx\"]\n",
    "del data[\"gradpz\"]\n",
    "\n",
    "# data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4756819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gradky', 'Ux', 'Uy', 'gradkx', 'gradkz', 'Uz', 'wallDistance', 'T_t',\n",
       "       'epsilon', 'k', 'p', 'T_k', 'DUDty', 'DUDtx', 'DUDtz', 'Ak_00', 'Ak_01',\n",
       "       'Ak_02', 'Ak_10', 'Ak_11', 'Ak_12', 'Ak_20', 'Ak_21', 'Ak_22',\n",
       "       'gradU_00', 'gradU_01', 'gradU_02', 'gradU_10', 'gradU_11', 'gradU_12',\n",
       "       'gradU_20', 'gradU_21', 'gradU_22', 'Akhat_00', 'Akhat_01', 'Akhat_02',\n",
       "       'Akhat_10', 'Akhat_11', 'Akhat_12', 'Akhat_20', 'Akhat_21', 'Akhat_22',\n",
       "       'Shat_00', 'Shat_01', 'Shat_02', 'Shat_10', 'Shat_11', 'Shat_12',\n",
       "       'Shat_20', 'Shat_21', 'Shat_22', 'S_00', 'S_01', 'S_02', 'S_10', 'S_11',\n",
       "       'S_12', 'S_20', 'S_21', 'S_22', 'R_00', 'R_01', 'R_02', 'R_10', 'R_11',\n",
       "       'R_12', 'R_20', 'R_21', 'R_22', 'Aphat_00', 'Aphat_01', 'Aphat_02',\n",
       "       'Aphat_10', 'Aphat_11', 'Aphat_12', 'Aphat_20', 'Aphat_21', 'Aphat_22',\n",
       "       'Rhat_00', 'Rhat_01', 'Rhat_02', 'Rhat_10', 'Rhat_11', 'Rhat_12',\n",
       "       'Rhat_20', 'Rhat_21', 'Rhat_22', 'Ap_00', 'Ap_01', 'Ap_02', 'Ap_10',\n",
       "       'Ap_11', 'Ap_12', 'Ap_20', 'Ap_21', 'Ap_22'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fab4d7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DUDty', 'Ap_20', 'Akhat_12', 'Ap_02', 'epsilon', 'Ux']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pearson\n",
    "matrix = data.corr()\n",
    "\n",
    "pos = matrix['p'].nlargest(4)[1:].index\n",
    "neg = matrix['p'].nsmallest(3).index\n",
    "features_P = list(pos) + list(neg)\n",
    "\n",
    "features_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd620bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['DUDty',\n",
       "  'Ap_20',\n",
       "  'Akhat_12',\n",
       "  'Shat_01',\n",
       "  'Shat_10',\n",
       "  'T_k',\n",
       "  'Akhat_02',\n",
       "  'T_t',\n",
       "  'Shat_11',\n",
       "  'DUDtx',\n",
       "  'Ap_02',\n",
       "  'epsilon',\n",
       "  'Ux',\n",
       "  'Akhat_21',\n",
       "  'k',\n",
       "  'Akhat_20',\n",
       "  'Shat_00',\n",
       "  'R_01',\n",
       "  'gradU_01',\n",
       "  'gradky'],\n",
       " 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pearson 8\n",
    "matrix = data.corr()\n",
    "\n",
    "pos = matrix['p'].nlargest(11)[1:].index\n",
    "\n",
    "neg = matrix['p'].nsmallest(10).index\n",
    "features_P20 = list(pos) + list(neg)\n",
    "\n",
    "features_P20,len(features_P20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9d2b472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gradU_10', 'DUDty', 'Ap_20', 'Ap_02', 'Aphat_02', 'Ux']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kendall\n",
    "matrix = data.corr(method=\"kendall\")\n",
    "\n",
    "pos = matrix['p'].nlargest(4)[1:].index\n",
    "\n",
    "neg = matrix['p'].nsmallest(3).index\n",
    "features_K = list(pos) + list(neg)\n",
    "\n",
    "features_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f84c7597",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gradU_10', 'DUDty', 'Ap_20', 'Ap_02', 'Aphat_02', 'Ux']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spearman\n",
    "matrix = data.corr(method=\"spearman\")\n",
    "\n",
    "pos = matrix['p'].nlargest(4)[1:].index\n",
    "\n",
    "neg = matrix['p'].nsmallest(3).index\n",
    "features_S = list(pos) + list(neg)\n",
    "\n",
    "features_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fda0987d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p           1.000000\n",
       "gradU_10    0.715101\n",
       "DUDty       0.708394\n",
       "Ap_20       0.644773\n",
       "Aphat_20    0.605612\n",
       "Name: p, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.p.nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a7173a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DUDty', 'Ap_20', 'Akhat_12', 'Ap_02', 'epsilon', 'Ux']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa4ec43c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer,loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m,metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(df_features)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mlen\u001b[39m(df_features))\n\u001b[1;32m     43\u001b[0m truth \u001b[38;5;241m=\u001b[39m df_target[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1653\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1649\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1652\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1653\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1655\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1656\u001b[0m     args,\n\u001b[1;32m   1657\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1658\u001b[0m     executing_eagerly)\n\u001b[1;32m   1659\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:379\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    378\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    388\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    392\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "df_features = data[features_P]\n",
    "df_target   = data[\"p\"]\n",
    "\n",
    "scaler_features = preprocessing.MinMaxScaler()\n",
    "scaler_target   = preprocessing.MinMaxScaler()\n",
    "\n",
    "df_features = pd.DataFrame(scaler_features.fit_transform(df_features),\n",
    "                          columns=features_P)\n",
    "df_target = pd.DataFrame(scaler_target.fit_transform(df_target.values.reshape(-1,1)),\n",
    "                          columns=[\"p\"])\n",
    "\n",
    "\n",
    "# Building my NN\n",
    "keras.backend.clear_session()\n",
    "\n",
    "#Ux, Uy\n",
    "input_layer = keras.layers.Input(shape=(6),name=\"input_layer\")\n",
    "\n",
    "#Hidden layers\n",
    "hidden1     = keras.layers.Dense(20,name=\"Hidden1\",kernel_initializer=\"lecun_normal\",\n",
    "                                activation=\"selu\")(input_layer)\n",
    "hidden2 = keras.layers.Dense(20,name='Hidden2', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden1)\n",
    "hidden3 = keras.layers.Dense(20,name='Hidden3', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden2)\n",
    "hidden4 = keras.layers.Dense(20,name='Hidden4', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden3)\n",
    "hidden5 = keras.layers.Dense(20,name='Hidden5', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden4)\n",
    "\n",
    "\n",
    "output_layer = keras.layers.Dense(1,name=\"output_layer\")(hidden5)\n",
    "\n",
    "model=keras.Model(inputs=[input_layer], outputs=[output_layer])\n",
    "# model.summary()\n",
    "# \n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(optimizer,loss=\"mse\",metrics=[\"mae\",\"mse\"])\n",
    "# \n",
    "history = model.fit([df_features],df_target,\n",
    "                    epochs=200,\n",
    "                    verbose= 0,\n",
    ")\n",
    "\n",
    "\n",
    "predictions = model.predict(df_features).reshape(len(df_features))\n",
    "truth = df_target['p']\n",
    "\n",
    "\n",
    "print(abs(predictions-truth).mean()*100, abs(predictions-truth).max()*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2274876d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_features = data[features_K]\n",
    "df_target   = data[\"p\"]\n",
    "\n",
    "scaler_features = preprocessing.MinMaxScaler()\n",
    "scaler_target   = preprocessing.MinMaxScaler()\n",
    "\n",
    "df_features = pd.DataFrame(scaler_features.fit_transform(df_features),\n",
    "                          columns=features_K)\n",
    "df_target = pd.DataFrame(scaler_target.fit_transform(df_target.values.reshape(-1,1)),\n",
    "                          columns=[\"p\"])\n",
    "\n",
    "\n",
    "# Building my NN\n",
    "keras.backend.clear_session()\n",
    "\n",
    "#Ux, Uy\n",
    "input_layer = keras.layers.Input(shape=(6),name=\"input_layer\")\n",
    "\n",
    "#Hidden layers\n",
    "hidden1     = keras.layers.Dense(20,name=\"Hidden1\",kernel_initializer=\"lecun_normal\",\n",
    "                                activation=\"selu\")(input_layer)\n",
    "hidden2 = keras.layers.Dense(20,name='Hidden2', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden1)\n",
    "hidden3 = keras.layers.Dense(20,name='Hidden3', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden2)\n",
    "hidden4 = keras.layers.Dense(20,name='Hidden4', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden3)\n",
    "hidden5 = keras.layers.Dense(20,name='Hidden5', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden4)\n",
    "\n",
    "\n",
    "output_layer = keras.layers.Dense(1,name=\"output_layer\")(hidden5)\n",
    "\n",
    "model=keras.Model(inputs=[input_layer], outputs=[output_layer])\n",
    "model.summary()\n",
    "# \n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(optimizer,loss=\"mse\",metrics=[\"mae\",\"mse\"])\n",
    "# \n",
    "history = model.fit([df_features],df_target,\n",
    "                    epochs=200,\n",
    "                    verbose= 0,\n",
    ")\n",
    "\n",
    "\n",
    "predictions = model.predict(df_features).reshape(len(df_features))\n",
    "truth = df_target['p']\n",
    "\n",
    "\n",
    "\n",
    "print(abs(predictions-truth).mean()*100, abs(predictions-truth).max()*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520ce38e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_features = data[features_S]\n",
    "df_target   = data[\"p\"]\n",
    "\n",
    "scaler_features = preprocessing.MinMaxScaler()\n",
    "scaler_target   = preprocessing.MinMaxScaler()\n",
    "\n",
    "df_features = pd.DataFrame(scaler_features.fit_transform(df_features),\n",
    "                          columns=features_S)\n",
    "df_target = pd.DataFrame(scaler_target.fit_transform(df_target.values.reshape(-1,1)),\n",
    "                          columns=[\"p\"])\n",
    "\n",
    "\n",
    "# Building my NN\n",
    "keras.backend.clear_session()\n",
    "\n",
    "#Ux, Uy\n",
    "input_layer = keras.layers.Input(shape=(6),name=\"input_layer\")\n",
    "\n",
    "#Hidden layers\n",
    "hidden1     = keras.layers.Dense(20,name=\"Hidden1\",kernel_initializer=\"lecun_normal\",\n",
    "                                activation=\"selu\")(input_layer)\n",
    "hidden2 = keras.layers.Dense(20,name='Hidden2', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden1)\n",
    "hidden3 = keras.layers.Dense(20,name='Hidden3', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden2)\n",
    "hidden4 = keras.layers.Dense(20,name='Hidden4', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden3)\n",
    "hidden5 = keras.layers.Dense(20,name='Hidden5', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden4)\n",
    "\n",
    "\n",
    "output_layer = keras.layers.Dense(1,name=\"output_layer\")(hidden5)\n",
    "\n",
    "model=keras.Model(inputs=[input_layer], outputs=[output_layer])\n",
    "model.summary()\n",
    "# \n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(optimizer,loss=\"mse\",metrics=[\"mae\",\"mse\"])\n",
    "# \n",
    "history = model.fit([df_features],df_target,\n",
    "                    epochs=200,\n",
    "                    verbose= 0,\n",
    ")\n",
    "\n",
    "\n",
    "predictions = model.predict(df_features).reshape(len(df_features))\n",
    "truth = df_target['p']\n",
    "\n",
    "\n",
    "\n",
    "print(abs(predictions-truth).mean()*100, abs(predictions-truth).max()*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11f4ae4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_features = data[features_P20]\n",
    "df_target   = data[\"p\"]\n",
    "\n",
    "scaler_features = preprocessing.MinMaxScaler()\n",
    "scaler_target   = preprocessing.MinMaxScaler()\n",
    "\n",
    "df_features = pd.DataFrame(scaler_features.fit_transform(df_features),\n",
    "                          columns=features_P20)\n",
    "df_target = pd.DataFrame(scaler_target.fit_transform(df_target.values.reshape(-1,1)),\n",
    "                          columns=[\"p\"])\n",
    "\n",
    "\n",
    "# Building my NN\n",
    "keras.backend.clear_session()\n",
    "\n",
    "#Ux, Uy\n",
    "input_layer = keras.layers.Input(shape=(20),name=\"input_layer\")\n",
    "\n",
    "#Hidden layers\n",
    "hidden1     = keras.layers.Dense(20,name=\"Hidden1\",kernel_initializer=\"lecun_normal\",\n",
    "                                activation=\"selu\")(input_layer)\n",
    "hidden2 = keras.layers.Dense(20,name='Hidden2', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden1)\n",
    "hidden3 = keras.layers.Dense(20,name='Hidden3', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden2)\n",
    "hidden4 = keras.layers.Dense(20,name='Hidden4', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden3)\n",
    "hidden5 = keras.layers.Dense(20,name='Hidden5', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden4)\n",
    "\n",
    "\n",
    "output_layer = keras.layers.Dense(1,name=\"output_layer\")(hidden5)\n",
    "\n",
    "model=keras.Model(inputs=[input_layer], outputs=[output_layer])\n",
    "model.summary()\n",
    "# \n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(optimizer,loss=\"mse\",metrics=[\"mae\",\"mse\"])\n",
    "# \n",
    "history = model.fit([df_features],df_target,\n",
    "                    epochs=200,\n",
    "                    verbose= 0,\n",
    ")\n",
    "\n",
    "\n",
    "predictions = model.predict(df_features).reshape(len(df_features))\n",
    "truth = df_target['p']\n",
    "\n",
    "\n",
    "\n",
    "print(abs(predictions-truth).mean()*100, abs(predictions-truth).max()*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcba5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d347c993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.65552163]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([df_features.iloc[0:1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de269f2",
   "metadata": {},
   "source": [
    "# Predict pressure using any model trainned by you, using 5 specific cases.\n",
    "* calculate mean absolute error\n",
    "* calculate maximum error\n",
    "* plot error as a funciont of points\n",
    "* Not allowed to use **PHLL_case**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99d608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
