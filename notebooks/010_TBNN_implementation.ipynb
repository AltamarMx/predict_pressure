{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df3484ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22cd096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"../data/kepsilon/kepsilon_BUMP_h20_Ak.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d59a80a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features and labels from the dataset: kepsilon\n",
      "Shape of basis tensor array: (230707, 10, 3, 3)\n",
      "Shape of invariant features array: (230707, 47)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 40\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape of invariant features array: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(Invariants\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#Load the additional scalars (N,5): \u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#    q[:,0] = Ratio of excess rotation to strain rate,\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#    q[:,1] = Wall-distance based Reynolds number, \u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#    q[:,2] = Ratio of turbulent time scale to mean strain time scale\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#    q[:,3] = Ratio of total Reynolds stress to 1/2 * normal Reynolds stress (TKE)\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m Scalars \u001b[38;5;241m=\u001b[39m \u001b[43mloadCombinedArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcases\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape of scalar features array: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(Scalars\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#Combine the invariants and scalars to form a feature set\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [19], line 15\u001b[0m, in \u001b[0;36mloadCombinedArray\u001b[0;34m(cases, field)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloadCombinedArray\u001b[39m(cases,field):\n\u001b[0;32m---> 15\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mdataset\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mdataset\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mcase\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mfield \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m case \u001b[38;5;129;01min\u001b[39;00m cases])\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "Cell \u001b[0;32mIn [19], line 15\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloadCombinedArray\u001b[39m(cases,field):\n\u001b[0;32m---> 15\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mcase\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mfield\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m case \u001b[38;5;129;01min\u001b[39;00m cases])\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/numpy/lib/npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[1;32m    430\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/numpy/lib/format.py:787\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mhasobject:\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# The array contained Python objects. We need to unpickle the data.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n\u001b[0;32m--> 787\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObject arrays cannot be loaded when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    788\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_pickle=False\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pickle_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    790\u001b[0m         pickle_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "# Loading data - select which cases to include in the training/validation set (commented out cases are held out)\n",
    "cases = ['DUCT_1100',\n",
    "         #'DUCT_2000',\n",
    "         #'DUCT_3500',\n",
    "         'PHLL_case_0p5',\n",
    "         #'PHLL_case_1p2',\n",
    "         'BUMP_h31',\n",
    "         #'BUMP_h38',\n",
    "         'CNDV_12600',\n",
    "         'CBFS_13700'\n",
    "         ]\n",
    "\n",
    "#Convenient functions for loading dataset\n",
    "def loadCombinedArray(cases,field):\n",
    "    data = np.concatenate([np.load('../data/'+dataset+'/'+dataset+'_'+case+'_'+field + '.npy') for case in cases])\n",
    "    return data\n",
    "\n",
    "def loadLabels(cases,field):\n",
    "    data = np.concatenate([np.load('../data/'+'labels/'+case+'_'+field + '.npy') for case in cases])\n",
    "    return data\n",
    "\n",
    "# Select RANS model\n",
    "dataset = 'kepsilon' \n",
    "\n",
    "print('Loading features and labels from the dataset: '+ dataset)\n",
    "\n",
    "#Load the set of ten basis tensors (N,10,3,3), from Pope \"A more general effective-viscosity hypothesis\" (1975).\n",
    "Tensors = loadCombinedArray(cases,'Tensors')\n",
    "print('Shape of basis tensor array: '+str(Tensors.shape))\n",
    "\n",
    "#Load the 47 invariants (N,47) used by Wu et al. \"Physics-informed machine learning approach for augmenting turbulence models: A comprehensive framework\" (2018)\n",
    "Invariants = loadCombinedArray(cases,'I1')\n",
    "print('Shape of invariant features array: '+str(Invariants.shape))\n",
    "\n",
    "#Load the additional scalars (N,5): \n",
    "#    q[:,0] = Ratio of excess rotation to strain rate,\n",
    "#    q[:,1] = Wall-distance based Reynolds number, \n",
    "#    q[:,2] = Ratio of turbulent time scale to mean strain time scale\n",
    "#    q[:,3] = Ratio of total Reynolds stress to 1/2 * normal Reynolds stress (TKE)\n",
    "Scalars = loadCombinedArray(cases,'q')\n",
    "print('Shape of scalar features array: '+str(Scalars.shape))\n",
    "\n",
    "#Combine the invariants and scalars to form a feature set\n",
    "Features = np.column_stack((Invariants,Scalars))\n",
    "print('Shape of combined features array: '+str(Features.shape))\n",
    "\n",
    "#Optional: remove outliers based on the number of standard deviations away from the mean. \n",
    "#Note: must be careful, as there are naturally large variations in flow features. Even a 5*stdev critera removes many valid near-wall points.\n",
    "# def remove_outliers(Features):\n",
    "#     stdev = np.std(Features,axis=0)\n",
    "#     means = np.mean(Features,axis=0)\n",
    "#     ind_drop = np.empty(0)\n",
    "#     for i in range(len(Features[0,:])):\n",
    "#         ind_drop = np.concatenate((ind_drop,np.where((Features[:,i]>means[i]+5*stdev[i]) | (Features[:,i]<means[i]-5*stdev[i]) )[0]))\n",
    "#     return ind_drop.astype(int)\n",
    "\n",
    "# outlier_removal_switch = 0\n",
    "# if outlier_removal_switch == 1:\n",
    "#     outlier_index = remove_outliers(Features)\n",
    "#     print('Found '+str(len(outlier_index))+' outliers in the input feature set')\n",
    "#     Features = np.delete(Features,outlier_index,axis=0)\n",
    "#     Tensors = np.delete(Tensors,outlier_index,axis=0)\n",
    "#     Labels = np.delete(Labels,outlier_index,axis=0)\n",
    "\n",
    "#Load the label set from DNS/LES:\n",
    "# Labels = loadLabels(cases,'b')\n",
    "#If desired, reshape the 3x3 symmetric anisotropy tensor into a 1x6 vector\n",
    "# Labels = np.delete(Labels.reshape((len(Labels),9)),[3,6,7],axis=1)\n",
    "# print('Shape of DNS/LES labels array: '+str(Labels.shape))\n",
    "\n",
    "# Split the datasets into training and validation\n",
    "# indices = np.arange(Features.shape[0])\n",
    "# input_shape = Features.shape[1]\n",
    "\n",
    "# x_train, x_val, y_train, y_val, ind_train, ind_val = train_test_split(Features, Labels, indices, test_size=0.2, random_state=10, shuffle=True)\n",
    "\n",
    "# basis_train = Tensors[ind_train]\n",
    "# basis_val = Tensors[ind_val]\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# x_train = scaler.fit_transform(x_train)\n",
    "# x_val = scaler.transform(x_val)\n",
    "\n",
    "# print(' ')\n",
    "# print('Training features:')\n",
    "# print(x_train.shape)\n",
    "# print('Training tensor basis:')\n",
    "# print(basis_train.shape)\n",
    "# print('Training labels:')\n",
    "# print(y_train.shape)\n",
    "# print(' ')\n",
    "# print('Validation features:')\n",
    "# print(x_val.shape)\n",
    "# print('Validation tensor basis:')\n",
    "# print(basis_val.shape)\n",
    "# print('Validation labels:')\n",
    "# print(y_val.shape)\n",
    "# print(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0453f0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(None, dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"../data/kepsilon/kepsilon_DUCT_1100_q.npy\"\n",
    "np.load(f,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b62d6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9216, 47)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"../data/kepsilon/kepsilon_DUCT_1100_I1.npy\"\n",
    "np.load(f).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4c6652d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9216, 47)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"../data/kepsilon/kepsilon_DUCT_1100_I2.npy\"\n",
    "np.load(f).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
